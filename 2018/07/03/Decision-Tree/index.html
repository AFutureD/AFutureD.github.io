<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.3.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="简述决策树本事上是一棵树，树的根节点包含了样本全集，从根出发到叶节点的路径对应了一个判定测试序列，而每个内部节点包含的样本集合则根据相应属性的测试结果而划分到子节点中。 注：决策树在 Coursera 和 Stanford 的公开课中并未提到，相关知识完全通过《机器学习》和互联网获得。 基本过程讲基本过程之前，先来搞懂“先验概率”、“后验概率”、“似然函数”。 先验概率：就是常识、经验或者统计方法">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="决策树（decision tree）">
<meta property="og:url" content="http://blog.afuture.me/2018/07/03/Decision-Tree/index.html">
<meta property="og:site_name" content="AFuture&#39;s Blog">
<meta property="og:description" content="简述决策树本事上是一棵树，树的根节点包含了样本全集，从根出发到叶节点的路径对应了一个判定测试序列，而每个内部节点包含的样本集合则根据相应属性的测试结果而划分到子节点中。 注：决策树在 Coursera 和 Stanford 的公开课中并未提到，相关知识完全通过《机器学习》和互联网获得。 基本过程讲基本过程之前，先来搞懂“先验概率”、“后验概率”、“似然函数”。 先验概率：就是常识、经验或者统计方法">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-07-03T09:14:28.351Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="决策树（decision tree）">
<meta name="twitter:description" content="简述决策树本事上是一棵树，树的根节点包含了样本全集，从根出发到叶节点的路径对应了一个判定测试序列，而每个内部节点包含的样本集合则根据相应属性的测试结果而划分到子节点中。 注：决策树在 Coursera 和 Stanford 的公开课中并未提到，相关知识完全通过《机器学习》和互联网获得。 基本过程讲基本过程之前，先来搞懂“先验概率”、“后验概率”、“似然函数”。 先验概率：就是常识、经验或者统计方法">






  <link rel="canonical" href="http://blog.afuture.me/2018/07/03/Decision-Tree/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>决策树（decision tree） | AFuture's Blog</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">AFuture's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>
  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.afuture.me/2018/07/03/Decision-Tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Andy Francis">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AFuture's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">决策树（decision tree）
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-07-03 14:50:09 / 修改时间：17:14:28" itemprop="dateCreated datePublished" datetime="2018-07-03T14:50:09+08:00">2018-07-03</time>
            

            
              

              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h2><p>决策树本事上是一棵树，树的根节点包含了样本全集，从根出发到叶节点的路径对应了一个判定测试序列，而每个内部节点包含的样本集合则根据相应属性的测试结果而划分到子节点中。</p>
<p>注：决策树在 Coursera 和 Stanford 的公开课中并未提到，相关知识完全通过《机器学习》和互联网获得。</p>
<h2 id="基本过程"><a href="#基本过程" class="headerlink" title="基本过程"></a>基本过程</h2><p>讲基本过程之前，先来搞懂“先验概率”、“后验概率”、“似然函数”。</p>
<p>先验概率：就是常识、经验或者统计方法所透露出的“因”的概率，$p$(原因)，就是先验概率。</p>
<p>后验概率：这种先知道结果，然后由结果估计原因的概率分布，$p$(原因|结果)，就是后验概率。</p>
<p>似然函数：这种先确定原因，根据原因来估计结果的固有性质的可能性（likelihood），是对固有性质的拟合程度，$L$(结果|原因)，就是似然估计。</p>
<p>于是有了贝叶斯公式：</p>
<p>$$<br>p(\theta|x)=\frac{p(x|\theta)p(\theta)}{p(x)}<br>$$</p>
<p>$x$ ：观察得到的数据（结果）</p>
<p>$\theta$ ：决定数据分布的参数（原因）</p>
<p>$p(\theta|x)$ ：后验概率（posterior probability）</p>
<p>$p(\theta)$ ：先验概率（prior probability）</p>
<p>$p(x|\theta)​$ ：似然估计（likelihood）</p>
<p>$p(x)$ ：evidence</p>
<p>懂了上述概念，接着讲讲基本流程，训练集 $D={(x_1,y_1),(x_2,y_2), \cdots , (x_m,y_m)}$; 属性集 $A={a_1,a_2, \cdots,a_d}$：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">函数 TreeGenerate(D,A)</span><br><span class="line">生成节点node:</span><br><span class="line">if D 中的样本全属于同一类别 C then</span><br><span class="line">    将node标记为C类叶子节点；return</span><br><span class="line">end if</span><br><span class="line">if A = ϕ OR D 中样本在 A 上取值相同 then</span><br><span class="line">    将 node 标记为叶节点，其类别标记为 D 中样本数最多的类；return</span><br><span class="line">end if</span><br><span class="line">从A中选则最优划分属性a*;</span><br><span class="line">for a* 的每一个值a*(v) do</span><br><span class="line">    为node生成一个分支；令Dv表示D中在a*上取值为a*(v)的样本子集；</span><br><span class="line">    if Dv 为空 then</span><br><span class="line">        将分支节点标记为叶节点，其类别标记为D中样本最多的类；return</span><br><span class="line">    else</span><br><span class="line">        以Tree(Dv,A\&#123;a*&#125;)为分支节点</span><br><span class="line">    end if</span><br><span class="line">end for</span><br></pre></td></tr></table></figure>
<p>决策数的生成是一个递归的过程，在决策树基本算法中有三种情况会导致递归返回：</p>
<ol>
<li>当前节点包含的样本种类属于同一类别，无需划分</li>
<li>当前样本属性集为空，或者所有样本在所有属性上的取值相同，无法划分</li>
<li>当前节点包含的样本集合为空，不能划分</li>
</ol>
<h2 id="划分选择"><a href="#划分选择" class="headerlink" title="划分选择"></a>划分选择</h2><p>上面的基本过程的的本质是构建一课树，核心是划分最优属性 $a_*$ ,且希望决策树的分支节点所包含的样本尽可能的属于同一类别，即节点的“纯度”尽可能高。</p>
<p>划分选择有多种算法，如：ID3、C4.5。</p>
<h3 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h3><p>在一开始 我们提一下熵。熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量。但是在信息世界，熵越高，则能传输越多的信息，熵越低，则意味着传输的信息越少。<br>信息熵(information entropy)是度量样本集合纯度最常用的一种指标，假定当前样本集合 $D$ 中第 $k$ 类样本所占的比例为 $p_k(k=1,2,\cdots , |\mathcal{Y}|)$ ，则 $D$ 的信息熵定义为：<br>$$<br>Ent(D)=-\sum^{|\cal{Y}|}_{k=1}p_k\log_2p_k .<br>$$<br>Ent(D)的值越小，则D的纯度越高。</p>
<p>为了找出“纯度最大”的属性，我们引入“信息增熵”，简单来说就是“信息熵”与“条件熵”的差值，即信息增益代表了在一个条件下，信息复杂度（不确定性）减少的程度；表明了此条件的重要性。再给出“信息增熵”的定义：</p>
<p>$$<br>Gain(D,a)=Ent(D)-\sum^{V}_{v=1}\frac{|D^v|}{|D|}Ent(D^v)<br>$$</p>
<p>所以：有了</p>
<p>$$<br>\DeclareMathOperator*{\argmax}{arg\,max}<br>a_* = \mathop{\argmax}_{a \in A}{Gain(D,a)}<br>$$</p>
<h3 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h3><p>为了解决信息增熵准则对可取数目较多的属性有所偏好，著名的 C4.5 决策树算法 [Quinlan,1993] 使用“增益率” （gain ration）来选择最优划分属性。</p>
<p>增益率定义为：<br>$$<br>Gain _ratio(D,a)=\frac{Gain(D,a)}{IV(a)}<br>$$<br>其中：<br>$$<br>\rm{IV}(a)=-\sum^V_{v=1}\frac{|\it{D}^{\it{v}}|}{|\it{D}|}\log_2{\frac{|\it{D}^{\it{v}}|}{|\it{D}|}}<br>$$<br>IV(a) 称为属性 a 的固有值，属性 a 的可能取值数目越多，则 IV(a) 的值通常会越大。增益率准则对取值数目较少的属性有所偏好。</p>
<p>因此，使用启发式：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。</p>
<h3 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h3><p> CART树(Classification and Regression Tree)使用基尼指数来选择属性的划分，通过基尼值来度量数据集的纯度<br>基尼值： </p>
<p>$$<br>\begin{align}<br>Gini(D)&amp;=\sum^{|\cal{Y}|}_{k=1}\sum_{k’\neq k}p_k p_{k’}\\<br>&amp;=1-\sum^{|\cal{Y}|}_{k=1}p_k^2<br>\end{align}<br>$$</p>
<p>反映了从数据集 $D$ 中取出两个样本，不为同一种类的概率，因此 Gini(D) 越小，数据集的纯度越高。 </p>
<p>转化成与“信息增熵”相似的定义：<br>$$<br>Gini\_index(D,a)=\sum^{V}_{v=1}\frac{|D^v|}{|D|}Gini(D^v)<br>$$<br>于是最优划分属性为：<br>$$<br>\DeclareMathOperator*{\argmin}{arg\,min}<br>a_* = \mathop{\argmin}_{a \in A}{Gini\_index(D,a)}<br>$$</p>
<h2 id="防止过拟合"><a href="#防止过拟合" class="headerlink" title="防止过拟合"></a>防止过拟合</h2><h3 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a>预剪枝</h3><p>预剪枝是在决策树生成的过程中，对每个结点在划分前先进行预估，若当前结点的划分不能使决策树泛化性能提升，则停止划分并将当前结点标记为叶节点。</p>
<p>即对比当前验证集精度与生成子决策树后的精度</p>
<h3 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h3><p>后剪枝是先从训练集中生成一颗完整的决策树，然后自底向上的对非叶子结点进行考察，若将改结点对应的子树替换为叶子结点能提高泛化能力，则进行替换。</p>
<p>即，对每一分支，对比当前精度与去掉决策子树的精度。</p>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>后剪枝决策树比预剪枝决策树保留了更多的分支，一般情况下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树，但后剪枝过程是生成完全决策树之后进行的，并且要自底向上地对书中的所有非叶子节点进行逐一考察，因此其训练时间开销比末剪纸决策树和预剪枝决策树都要大得多。</p>
<h2 id="连续值缺失值处理"><a href="#连续值缺失值处理" class="headerlink" title="连续值缺失值处理"></a>连续值缺失值处理</h2><h3 id="连续值处理"><a href="#连续值处理" class="headerlink" title="连续值处理"></a>连续值处理</h3><p>由于连续属性的可能取值不再有限，因此不能直接根据连续属性的可能取值进行划分。我们可以使用离散化技术对其进行处理。<br>二分法：<br>给定样本集 $D$ ，和连续属性 $a$ ，$a$ 在 $D$ 上出现了 $n$ 个不同的取值，<br>将其排序 ${a_1,a_2,\cdots,a_n}$ ，然后基于划分点 $t$ 将样本划分为 $D−t$ 和 $D+t$ ，$D−t$ 包括了在属性 $a$ 上取值小于 $t$ 的样本，$D+t$ 反之。即<br>$$<br>T_a={\frac{a_i+a_{i+1}}{2}|1 \leq i \leq n−1}<br>$$<br>通常我们取区间 $[a^i,a^{a+1})$ 的中位点作为候选划分点。</p>
<p>然后有：<br>$$<br>\DeclareMathOperator*{\argmin}{arg\,min}<br>\begin{align}<br>Gain(D,a)&amp;=\max \limits_{t \in T_a} Gain(D,a,t)\\<br>&amp;=\max \limits_{t \in T_a}  Ent(D)-\sum_{\lambda in {-,+}} \frac{|D^{\lambda}_t|}{|D|}Ent(D^{\lambda}_t)<br>\end{align}<br>$$</p>
<h3 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h3><p>现实任务中常常会遇到不完整的样本，也就是样本中的某些属性值缺失的情况，最简单的方法是直接去除缺失的数据，但是这是对数据信息的极大浪费，我们可以考虑下利用有缺失属性值的样本来进行学习。<br>需解决的问题：</p>
<ol>
<li>在属性值缺失的情况下进行划分属性的选择</li>
<li>给定划分属性，若样本在该属性上的值缺失，如何进行划分</li>
</ol>
<p>给定训练集 $D$ ,属性集 $a$ ,令 $\tilde{D}$ 表示 $D$ 中在属性 $a$ 上没有缺失值的样本子集。</p>
<p>对问题一：可依据 $\tilde{D}$ 来判断属性的优劣。假定属性 $a$ 有 $V$ 个可取的值 ${a^1,a^2, \cdots , a^V}$ ，令 $\tilde{D}^v$ 表示 $\tilde{D}$ 中在属性 $a$ 上的取值为 $a^v$ 的样本集， $\tilde{D}_k$  表示 $\tilde{D}$ 中属于第 $k$ 类的样本子集。</p>
<p>显然有 $ \tilde{D} = \bigcup^{|\cal{Y}|}_{k=1}\tilde{D}_k,\tilde{D} = \bigcup^{|V|}_{v=1}\tilde{D} ^v$ 。</p>
<p>假定给每个样本一个权重 $w_x$ ，并定义：</p>
<p>$$<br>\begin{align}<br>\rho&amp;=\frac{\sum_{x \in  \tilde{D} }w_x}{\sum_{x \in D}w_x}\\<br>\tilde{p}_k&amp; = \frac{\sum_{x \in  \tilde{D}_k }w_x}{\sum_{x \in D}w_x} &amp;(1 \leq k \leq |\cal{Y}|)\\<br>\tilde{r}_v&amp; = \frac{\sum_{x \in  \tilde{D}^v }w_x}{\sum_{x \in D}w_x} &amp;(1 \leq k \leq |\cal{Y}|)<br>\end{align}<br>$$</p>
<p>$\rho$ ：在属性 $a$ 中 ，无缺失值所占样本比例；</p>
<p>$\tilde{p}_k$ ：无缺失值样本中第 $k$ 类所占的比例；</p>
<p>$\tilde{r}_v$ ：无缺失值样本中在属性 $a$ 上的取值 $a^v$ 的样本所占比例 </p>
<p>显然有，$\sum^{ |\cal{Y}|}_{k=1} \tilde{p}_k=1,\sum^{ |V|}_{c=1} \tilde{r}_v=1$ 。</p>
<p>于是可以推广信息增益的计算式为：<br>$$<br>\begin{align}<br>Gain(D,a)&amp;=\rho \times Gain(\tilde{D},a)\\<br>&amp;=\rho \times \left(  Ent \left( \tilde{D} \right)-\sum^{V}_{v=1}\tilde{r}_vEnt(\tilde{D} ^v) \right)<br>\end{align}<br>$$<br>其中：<br>$$<br>Ent(\tilde{D}) = -\sum^{|\cal{Y}|}_{k=1}\tilde{p}_k \log_2\tilde{p}_k<br>$$<br>对问题二，样本 $x$ 在属性 $a$ 上的取值缺失，则将 $x$ 划分到所有叶子结点中，将权值变为 $\tilde{r}_v \cdot w_x$ 意思将同一个样本以不同的概率划入到同的子结点中去。</p>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/03/Logistic-Regression/" rel="next" title="Logistic Regression">
                <i class="fa fa-chevron-left"></i> Logistic Regression
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/03/Normalization-and-Regularization/" rel="prev" title="Normalization and Regularization">
                Normalization and Regularization <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Andy Francis</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">30</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">分类</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">31</span>
                    <span class="site-state-item-name">标签</span>
                  
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#简述"><span class="nav-number">1.</span> <span class="nav-text">简述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基本过程"><span class="nav-number">2.</span> <span class="nav-text">基本过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#划分选择"><span class="nav-number">3.</span> <span class="nav-text">划分选择</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ID3"><span class="nav-number">3.1.</span> <span class="nav-text">ID3</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#C4-5"><span class="nav-number">3.2.</span> <span class="nav-text">C4.5</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CART"><span class="nav-number">3.3.</span> <span class="nav-text">CART</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#防止过拟合"><span class="nav-number">4.</span> <span class="nav-text">防止过拟合</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#预剪枝"><span class="nav-number">4.1.</span> <span class="nav-text">预剪枝</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#后剪枝"><span class="nav-number">4.2.</span> <span class="nav-text">后剪枝</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优缺点"><span class="nav-number">4.3.</span> <span class="nav-text">优缺点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#连续值缺失值处理"><span class="nav-number">5.</span> <span class="nav-text">连续值缺失值处理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#连续值处理"><span class="nav-number">5.1.</span> <span class="nav-text">连续值处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缺失值处理"><span class="nav-number">5.2.</span> <span class="nav-text">缺失值处理</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Andy Francis</span>

  

  
</div>




  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动 v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Gemini</a> v6.3.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.3.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.3.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.3.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



	





  





  










  





  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  

</body>
</html>
